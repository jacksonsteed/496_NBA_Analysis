---
title: "classification_jethro_496"
author: "Jethro Infante"
date: "2023-10-31"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(stats)
```

Some preparation
```{r}
winshares_unique <- read_csv("winshares_with_winpct.csv")
final <- read_csv("stuff_jethro_prepped.csv")

winshares_unique
final

merged_data <- merge(final, winshares_unique, by = c("SEASON", "PLAYER_NAME", "gameDate")) 
merged_data <- merged_data %>% select(SEASON, MIN, FGA, OREB, TO, FTA, PTS, PLUS_MINUS, Team_Points, Team_Won, PrevGameMin, seasonPart, MinDiff, WS, WS_bin, DWS, DWS_bin, OWS, OWS_bin, DaysBetweenGames, `Height (cm)`)



merged_data

write_csv(merged_data, "last_hope.csv")
```

```{r}
# Get rid of everything i dont care about
data <- read_csv("last_hope.csv")

# OLD WAY OF CALCULATING PERFORMANCE
# Define the weights for each performance category
#weights_overall <- c(0.4, 0.3, 0.2, 0.1)
#weights_offensive <- c(0.5, 0.3, 0.2)
#weights_defensive <- c(0.4, 0.3, 0.3)

# Create the performance indicators
#data$Overall_Performance <- rowSums(data[, c("PTS", "REB", "AST", "STL")] * weights_overall)
#data$Offensive_Performance <- rowSums(data[, c("PTS", "FGM", "AST")] * weights_offensive)
#data$Defensive_Performance <- rowSums(data[, c("STL", "BLK", "REB")] * weights_defensive)

#CALCULATING OFFENSIVE RATING HERE
data$OffensiveRating <- (data$PTS / (data$FGA + 0.44 * data$FTA + data$TO)) * 100
data <- data %>% mutate(ORTG_bin = cut_number(OffensiveRating, n = 6, labels = c("Bin1", "Bin2", "Bin3", "Bin4", "Bin5", "Bin6")), PLUS_MINUS_bin = cut_number(PLUS_MINUS, n = 6, labels = c("Bin1", "Bin2", "Bin3", "Bin4", "Bin5", "Bin6")), MinDiff_bin = cut_number(MinDiff, n = 6, labels = c("Bin1", "Bin2", "Bin3", "Bin4", "Bin5", "Bin6")))

data <- na.omit(data)

# Calculate approximate bin ranges for ORTG
bin_ranges <- data %>%
  group_by(ORTG_bin) %>%
  summarize(min_range = min(OffensiveRating),
            max_range = max(OffensiveRating))
bin_ranges

# Calculate approximate bin ranges for WS
bin_ranges <- data %>%
  group_by(WS_bin) %>%
  summarize(min_range = min(WS),
            max_range = max(WS))
bin_ranges

# Calculate approximate bin ranges for WS
bin_ranges <- data %>%
  group_by(OWS_bin) %>%
  summarize(min_range = min(OWS),
            max_range = max(OWS))
bin_ranges

# Calculate approximate bin ranges for WS
bin_ranges <- data %>%
  group_by(DWS_bin) %>%
  summarize(min_range = min(DWS),
            max_range = max(DWS))
bin_ranges

# Calculate approximate bin ranges for PLUS_MINUS
bin_ranges <- data %>%
  group_by(PLUS_MINUS_bin) %>%
  summarize(min_range = min(PLUS_MINUS),
            max_range = max(PLUS_MINUS))
bin_ranges

# Calculate approximate bin ranges for MinDiff
bin_ranges <- data %>%
  group_by(MinDiff_bin) %>%
  summarize(min_range = min(MinDiff),
            max_range = max(MinDiff))
bin_ranges

# Performance metrics choose here what to keep or remove
data$FGA <- NULL
data$FTA <- NULL
data$OREB <- NULL
data$TO <- NULL
#data$PTS <- NULL
data$OffensiveRating <- NULL
data$WS <- NULL
data$OWS <- NULL
data$DWS <- NULL
data$ PLUS_MINUS <- NULL

data <- na.omit(data)
data
```

Create some bins
```{r}
# Define the number of bins
num_bins <- 6  # You can adjust this value as needed
bin_labels <- c("Bin1", "Bin2", "Bin3", "Bin4", "Bin5", "Bin6")

# List of columns you want to bin
columns_to_bin <- c("Team_Points")
nba_data_binned <- data %>%
  mutate(across(all_of(columns_to_bin), 
                ~cut_number(., n = 6, labels = bin_labels), 
                .names = "{col}_Bin"))

# Define the columns to bin using numeric values
columns_to_bin1 <- c("MIN", "PrevGameMin")

# Filter the data first
nba_data_binned <- nba_data_binned %>%
  filter(as.numeric(gsub("^(\\d+):.*", "\\1", MIN)) <= 60, as.numeric(gsub("^(\\d+):.*", "\\1", PrevGameMin)) <= 60) %>%
  
# Extract the first number before the ":" (if it exists), create bins, and replace original columns
  mutate(across(all_of(columns_to_bin1), .fns = list(Value = ~as.numeric(gsub("^(\\d+):.*", "\\1", .))), .names = "{col}_Numeric_Value")) %>%
   mutate(across(ends_with("_Numeric_Value"), 
                ~cut_number(., n = 6, labels = bin_labels), 
                .names = "{col}_Bin"))

# Calculate approximate bin ranges for MIN
bin_ranges <- nba_data_binned %>%
  group_by(MIN_Numeric_Value_Bin) %>%
  summarize(min_range = min(MIN_Numeric_Value),
            max_range = max(MIN_Numeric_Value))
bin_ranges

# Calculate approximate bin ranges for PrevGameMin
bin_ranges <- nba_data_binned %>%
  group_by(PrevGameMin_Numeric_Value_Bin) %>%
  summarize(min_range = min(PrevGameMin_Numeric_Value),
            max_range = max(PrevGameMin_Numeric_Value))
bin_ranges

# Calculate approximate bin ranges for PrevGameMin
bin_ranges <- nba_data_binned %>%
  group_by(Team_Points_Bin) %>%
  summarize(min_range = min(Team_Points),
            max_range = max(Team_Points))
bin_ranges

nba_data_binned$PrevGameMin_Numeric_Value <- NULL
nba_data_binned$MIN_Numeric_Value <- NULL
nba_data_binned$MIN <- NULL
nba_data_binned$PrevGameMin <- NULL
nba_data_binned$PTS <- NULL
nba_data_binned$SEASON <- NULL
nba_data_binned$Team_Points <- NULL
#nba_data_binned$Team_Won <- NULL
nba_data_binned$MinDiff <-NULL

nba_data_binned
```

Create decision trees
```{r}
#check_it <- nba_data_binned
#check_it <- nba_data_binned %>% filter(OWS_bin == "Bin5")
check_it <- nba_data_binned %>% filter(WS_bin %in% c("Bin4"))

check_it$WS_bin <- NULL
check_it$OWS_bin <- NULL
check_it$DWS_bin <- NULL
#check_it$Team_Points_Bin <- NULL
#check_it$MIN_Numeric_Value_Bin <- NULL
#check_it$PLUS_MINUS_bin <- NULL
check_it$ORTG_bin <- NULL

check_it
summary(check_it)

# Set a random seed for reproducibility
set.seed(123)

# Split the data into a training set (70%) and a test set (30%)
index <- createDataPartition(check_it$PLUS_MINUS_bin, p = 0.7, list = FALSE) # change what youre looking for here
train_data <- check_it[index, ]
test_data <- check_it[-index, ]

# Create the decision tree model using rpart
decision_tree_model <- rpart(PLUS_MINUS_bin ~ ., data = train_data, method = "class") # change what youre looking for here

# Visualize the decision tree using rpart.plot
rpart.plot(decision_tree_model, box.palette = "Blues")

# Predict on the test set
predictions <- predict(decision_tree_model, test_data, type = "class")

# Create a confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data$PLUS_MINUS_bin) # change what youre looking for here
confusion_matrix
accuracy <- confusion_matrix$overall["Accuracy"]

# Print the accuracy
cat("Accuracy:", accuracy, "\n")


# Load ggplot2 library
library(ggplot2)

# Convert confusion matrix to a data frame
confusion_df <- as.data.frame(as.table(confusion_matrix$table))

# Rename columns for clarity
names(confusion_df) <- c("Predicted", "Actual", "Count")

# Create heatmap using ggplot2
ggplot(confusion_df, aes(x = Predicted, y = Actual, fill = Count)) +
  geom_tile() +
  geom_text(aes(label = Count), vjust = 1, color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Confusion Matrix Heatmap",
       x = "Predicted",
       y = "Actual")
```